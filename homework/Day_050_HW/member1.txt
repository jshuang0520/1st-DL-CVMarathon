anna
深度學習電腦視覺期末專題
2020/05/21


一 專題摘要

浣熊與袋鼠辨識模型

本次期末專題主題建立一個模型同時能辨識出浣(raccoon)

與袋鼠(kangaroo)的類別與位置

二實作方法介紹

Yolov3_karas

首先利用lableImg工具標注自己的圖片，生成對應的xml檔，具體標注方法這裡不再贅述，然後按照以下的格式創建VOC資料集, 其中，把剛才標注好的JPG圖片放入JPEGImages資料夾中，將xml標注文件放在Annotations資料夾中










接下來要在Main中生成r個txt檔，其中test.txt是測試集，train.txt是訓練集，val.txt是驗證集，trainval.txt是訓練和驗證集。為了操作方便，我們直接在VOC2007下新建一個name.py的檔，內容如下

import os

import random

import sys

'''

if len(sys.argv) < 2:

print("no directory specified, please input target directory")

exit()

'''

#root_path = sys.argv[1]

root_path = "C:\\Users\\reyna\\Yolo\\VOCdevkit\\VOC2007"





xmlfilepath = root_path + '\\Annotations'



txtsavepath = root_path + '\\ImageSets\\Main'



if not os.path.exists(root_path):

print("cannot find such directory: " + root_path)

exit()



if not os.path.exists(txtsavepath):

os.makedirs(txtsavepath)



trainval_percent = 0.9

train_percent = 0.8

total_xml = os.listdir(xmlfilepath)

num = len(total_xml)

list = range(num)

tv = int(num * trainval_percent)

tr = int(tv * train_percent)

trainval = random.sample(list, tv)

train = random.sample(trainval, tr)



print("train and val size:", tv)

print("train size:", tr)



ftrainval = open(txtsavepath + '/trainval.txt', 'w')

ftest = open(txtsavepath + '/test.txt', 'w')

ftrain = open(txtsavepath + '/train.txt', 'w')

fval = open(txtsavepath + '/val.txt', 'w')



for i in list:

name = total_xml[i][:-4] + '\n'

if i in trainval:

ftrainval.write(name)

if i in train:

ftrain.write(name)

else:

fval.write(name)

else:

ftest.write(name)



ftrainval.close()

ftrain.close()

fval.close()

ftest.close()








接下來修改yolov3資料夾下的voc_annotation.py檔，將classes修改為自己的類別，然後運行生成yolo格式的標注檔

python voc_annotation.py

這樣在主目錄下生成以下三個檔



2007_test.txt

2007_train.txt

2007_val.txt



yolo預訓練模型



• wget https://pjreddie.com/media/files/yolov3.weights

• python convert.py yolov3.cfg yolov3.weights model_data/yolo.h5

修改類別檔



找到model_data/voc_classes.txt檔，將裡邊的類別修改為自己的類別












修改yolov3.cfg



yolov3的filters計算方式:

filters=(classes+5)*3

#(1+5)*3=18



decay=0.005

[convolutional]

size=1

stride=1

pad=1

filters=21

activation=linear





[yolo]

mask = 6,7,8

anchors = 10,13, 16,30, 33,23, 30,61, 62,45, 59,119, 116,90, 156,198, 373,326

classes=2

num=9

jitter=.3

ignore_thresh = .5

truth_thresh = 1

random=0












開始訓練

import numpy as np

import keras.backend as K

from keras.layers import Input, Lambda

from keras.models import Model

from keras.optimizers import Adam

from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping

from train import get_classes, get_anchors, create_model, create_tiny_model, data_generator, data_generator_wrapper



from PIL import ImageFile

ImageFile.LOAD_TRUNCATED_IMAGES = True



annotation_path = '2007_train.txt' # 轉換好格式的標註檔案

log_dir = 'logs/000/' # 訓練好的模型儲存的路徑

classes_path = 'model_data/voc_classes.txt'

anchors_path = 'model_data/yolo_anchors.txt'

class_names = get_classes(classes_path)

num_classes = len(class_names)

anchors = get_anchors(anchors_path)



input_shape = (416,416) # multiple of 32, hw



is_tiny_version = len(anchors)==6 # default setting

if is_tiny_version:

   model = create_tiny_model(input_shape, anchors, num_classes,

       freeze_body=2, weights_path='model_data/tiny_yolo_weights.h5')

else:

   model = create_model(input_shape, anchors, num_classes,

       freeze_body=2, weights_path='model_data/yolo_weights.h5') # make sure you know what you freeze



logging = TensorBoard(log_dir=log_dir)

checkpoint = ModelCheckpoint(log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',

   monitor='val_loss', save_weights_only=True, save_best_only=True, period=3)

reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)

early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)



# 分為 training 以及 validation

val_split = 0.1

with open(annotation_path) as f:

   lines = f.readlines()

np.random.seed(10101)

np.random.shuffle(lines)

np.random.seed(None)

num_val = int(len(lines)*val_split)

num_train = len(lines) - num_val



# Train with frozen layers first, to get a stable loss.

# Adjust num epochs to your dataset. This step is enough to obtain a not bad model.

# 一開始先 freeze YOLO 除了 output layer 以外的 darknet53 backbone 來 train

if True:

   model.compile(optimizer=Adam(lr=1e-3), loss={

# use custom yolo_loss Lambda layer.

'yolo_loss': lambda y_true, y_pred: y_pred})



   batch_size = 16

print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))

# 模型利用 generator 產生的資料做訓練，強烈建議大家去閱讀及理解 data_generator_wrapper 在 train.py 中的實現

model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),

           steps_per_epoch=max(1, num_train//batch_size),

           validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),

           validation_steps=max(1, num_val//batch_size),

           epochs=50,

           initial_epoch=0,

           callbacks=[logging, checkpoint])



model.save_weights(log_dir + 'trained_weights_stage_1.h5')



# Unfreeze and continue training, to fine-tune.

# Train longer if the result is not good.

if True:

# 把所有 layer 都改為 trainable

for i in range(len(model.layers)):

       model.layers[i].trainable = True

   model.compile(optimizer=Adam(lr=1e-4), loss={'yolo_loss': lambda y_true, y_pred: y_pred}) # recompile to apply the change

print('Unfreeze all of the layers.')



   batch_size = 16 # note that more GPU memory is required after unfreezing the body

print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))

model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),

       steps_per_epoch=max(1, num_train//batch_size),

       validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),

       validation_steps=max(1, num_val//batch_size),

       epochs=100,

       initial_epoch=50,

       callbacks=[logging, checkpoint, reduce_lr, early_stopping])

model.save_weights(log_dir + 'trained_weights_final.h5')












1. YOLO會把圖先平均分成S×S格，這邊假設S = 5，圖會被平均分成5×5格(如上左圖)，每一格在英文被稱為grid cell (大小為20×20)。

整體的概念就是如果要「被偵測的物件中心」落在哪一個grid cell，那個grid cell就要負責偵測這個物件。

2. 每個grid cell必須要負責預測「B個bounding boxes」和「屬於每個類別的機率」，每個bounding box會帶有5個預設值(x, y, w, h, and confidence)

3. 作者舉PASCAL VOC在執行YOLO的例子，他設定S=7，B=2，PASCAL VOC有20個物件的類別，所以C=20。一開始有說YOLO最後的tensor為S×S×(B×5+C)。



Bounding Box正規化

Activation function

三、成果展示











四、結論

IoU(Intersection over Union)
Intersection over Union是一種測量在特定資料集中檢測相應物體準確度的一個標準。我們可以在很多物體檢測挑戰中，例如PASCAL VOC challenge中看多很多使用該標準的做法。
IoU是一個簡單的測量標準，只要是在輸出中得出一個預測範圍(bounding boxex)的任務都可以用IoU來進行測量。為了可以使IoU用於測量任意大小形狀的物體檢測，我們需要：
1、 ground-truth bounding boxes
2、我們的演算法得出的結果範圍。
也就是說，這個標準用於測量真實和預測之間的相關度，相關度越高，該值越高。
