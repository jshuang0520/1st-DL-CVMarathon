侯宇哲
深度學習與電腦視覺期末專題_侯宇哲
2020/05/19
一、專題摘要

在生產過程中，不論科技業或是傳統製造業一定會有成品或半成品的檢驗站，在製造業中產品的檢驗大多依賴人工，以視覺、觸覺或是儀器來測量產品是否有瑕疵，但人工的缺點是人會疲勞，當疲勞時專注力與判斷力容易下降，就會發生漏檢，因而影響產品之良率，嚴重的話可能會影響公司的商譽。現今科技業面對此問題大多使用以傳統電腦視覺法建立的瑕疵辨識系統來取代人工，但這種系統往往設置成本高，而高設置成本更是讓大多製造業望之卻步。



以人工智慧深度學習為基礎來進行影像辨識則可以減少以上提到的問題，不需要高昂的精密鏡頭，或是特殊光源的打光，並且隨著資料的累積，系統的準確度也會隨之上升，並且系統彈性高，不需要因為檢驗產品的更換而更換鏡頭或光源，只需要更換相對應的模型即可。物件偵測法在大物件上的辨識率很高，但是在小物件上容易出現overfitting，因此如果需要便是的物件太小，容易出現辨識率下降或是辨識失敗的問題出現，此為物件偵測一大缺點。



本次研究提出一種二階段之物件偵測演算法，來建立一個自動瑕疵偵測系統，利用兩階段的方式來對影像進行辨識，減少模型overfitting的機率，提高小物件之辨識率。利用此系統來輔助人工的檢測，以降低人工的疲勞，進而降低漏檢率以及減少不必要的人力成本。此作法與傳統電腦視覺最大的差異在於設置成本低並且系統彈性高，讓產業能夠以低成本架設此系統，以降低人力成本支出。



二、實作方法介紹

為了進行深度學習，必須要蒐集大量有瑕疵的工件照片，因此需在產線上架設攝影機，並且人工拍下有瑕疵之工件，以供後續使用，經兩個月的蒐集，共蒐集到3625張的瑕疵照。



蒐集到的影像資料並不能馬上進行使用，因為本研究是利用物件偵測法來做辨識系統，因此需將訓練影像上的瑕疵點標記出來，在送入訓練模型中。影像標註需要用到名為Labelimg的軟體，該軟體能夠在原有的影像上進行標註，並且生成對應的標注資料儲存在XML檔中，該XML檔會記錄影像的名稱、儲存路徑、影像大小，以及瑕疵點的位置及種類。

為了解決YOLOv3在小物件辨識率不高以及相似物件上容易有overfitting出現，本研究使用二階段的演算法來解決此問題，一般物件偵測系統都是利用一個模型來學習所有需辨識的類別之特徵，然後再以該模型對影像進行物件偵測，二階段演算法係指利用兩階段多模型的方式來進行學習與辨識，將我們所需判別之瑕疵分為四個群組。

然後將模型分為兩個階段，第一階段包含一個模型，其目的是將四個群組分類出來，然後將不易分辨的群組三與群組四送入第二階段，第二階段包含兩個模型，其目的是針對兩個群組內不易分辨之瑕疵進行分類，整體架構如下圖所示

                         ___ Pit
                        |___ Granular
input image -> YoLov3 --|                                         | Scratch
                        |___ 群組 Scratch + Water mark -> YoLov3 ->| Water mark
                        |
                        |                                         | Orange peel
                        |___ 群組 Orange peel + Crater -> YoLov3 ->| Crater


在資料標記時便按照此分類方式去對訓練影像進行標記，如瑕疵屬於火山口或凹洞，即將其框起並標記為該屬性之瑕疵即可，如瑕疵屬於刮痕或水痕，則只需將其標記成群組三即可，不須區分兩種瑕疵，如瑕疵屬於群組四也是相同作法。其目的在於第一階段的模型只需要學會判別四大類的瑕疵即可，並不需要分辨出細部的瑕疵，刮痕與水痕的瑕疵特徵非常相似，橘皮與顆粒的瑕疵特徵也很相似，故如果在同一模型內要辨識出這些瑕疵，可能會造成模型overfitting，導致測試時無法正確辨識，因此將相似的瑕疵在第一階段視為同一種瑕疵，然後在第二階段時，再將其分開標記出來，即可避免模型overfitting，提升辨識率。

第二階段的模型是要將群組三和群組四做內部分辨。因此第二階段需分為兩個模型以對應兩個群組，在訓練資料上也只需對兩個群組的影像進行標記即可，將群組三以及群組四的影像分別進行標記，產生三個資料集對應三個訓練模型。

成以上前置作業後即可進入模型的訓練，本研究使用每批量64張影像進行5000次迭代訓練，本文使用二階段的物件偵測，因此需要訓練兩個模型，訓練完成後即可檢視訓練結果，將帶有瑕疵之影像透過訓練後的模型權重來對瑕疵進行定界及判斷瑕疵類別，第一階段的目標是能夠將瑕疵分為四個群組，第二階段的目的是將群組三與群組四之瑕疵進行分辨。如分辨率不佳，意即物件的Map值過低時，即回頭調整模型訓練超參數，將學習速率改為線性降低，並且如果5個跌代內沒有演化出區域最佳權重時，將學習速率在進一步降低，已減低峽谷效應帶來之影響，加快找到全域近似最佳解的速度。另外還能調整其他超參數，來調整模型的訓練已獲得更好的模型。



三、成果展示





瑕疵辨識正確率還可以，但是信心度仍不是太好，如果能再進一步蒐集到更多瑕疵照，應該可以再提升。



四、結論

經過多次調整後所得出的深度學習模型辨識率可達92%，利用二階段的演算方式可以降低YOLO模型不易辨識小物件之缺點，本文準備了1000張沒有給模型訓練的瑕疵照用來當作測試資料集，透過辨識系統將測試資料集的影像，送入第一階段的模型，然後再將輸出的群組三與群組四之影像送入第二階段之模型，然後再將其輸出的影像蒐集做整理，計算其分類瑕疵的辨識率，以目前之辨識率要完全取代人力可行性還不夠，目前該系統是以輔助人工檢測為主，如果能夠取得更多的影像資料，便可將辨識率提升，以達到最終目的，自動瑕疵偵測系統。



五、期末專題作者資訊

1. https://github.com/steven47786

2. 侯宇哲

