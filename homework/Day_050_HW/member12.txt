深度學習與電腦視覺期末專題__王韋欽
2020/02/29
深度學習與電腦視覺期末專題_王韋欽



2020/02/25







一、專題摘要 (解釋實作與說明需要解決的問題，限300~500字。)



期末專題主題 : 使用Yolo3進行設備電氣控制箱之各軸伺服器的配線缺漏檢查




期末專題基本目標 :  
(1) 在各生產機台設備中,要達成自動控制的功能,需仰賴主控電腦,可程式控制器,各軸伺服器的連接才能達成,以上這些設備,被整合在電氣控制箱之中,如下圖所示。



(2) 我司是生產及販賣及維修可程式控制器,各軸伺服器相關產品,經常遇到客戶因為各軸伺服器的相關配線失誤缺漏,造成軸伺服器的故障,常與客戶多次說明,請確認配線是否失誤缺漏,但客戶只要換過一批配盤人員,或是趕工時,此類問題仍層出不窮,如下圖所示。




(3) 因此,想開發出一套能幫助客戶與配線後,送電之前,可以快速檢查缺漏配線(四條配線中的CN2,CN3,Power-cable,Motor-cable少了那些) 的軟體及器材,幫助客戶減少損失,同時降低我司維修人員的工作負擔。



(4)因正常設備各軸的大小容量不同,軸伺服器的型態也不同,相片的差異也比較大,所以先開發常用容量的單軸伺服器配線檢查的模組,先累積基礎,以後有機會再進行擴充。





二、實作方法介紹 (介紹使用的程式碼、模組，並附上實作過程與結果的截圖，需圖文並茂。)



使用的程式碼介紹:
(1) 主要參考: https://www.twblogs.net/a/5cb7caf4bd9eee0eff45a24e  ,按照其中的步驟及程序進行,主要原因是一直沒有真正接觸最底層的網絡構建和訓練，之前在Darknet官網上看到有關於訓練yolo模型的方法，是基於linux操作系統的,我對於Linux不熟,所以沒採用。

(2) 深度學習框架使用Keras,在windows10上配合anaconda下,進行訓練及測試。



使用的模組介紹: 使用Yolov3_Keras版本的模型。
(1)開始訓練時先導入keras-yolo3-master的預設權重檔

(2)第四次訓練開始導入自己訓練後的權重檔(前三次因為不熟悉train的方式,都是從0開始)

(3)因自己的筆電為舊型的MSI GE602QD,GPU為NVIDIA GTX950M,在深度學習上較不給力,用預設訓練參數Epoch=500,Batch size=10時,在Epoch=1就自動跳出,查尋後發現是RAM及GPU不足,因此將Batch size=2, Epoch=15, Random=0時仍會當機,故前三次訓練Batch size=2, Epoch=10,第四次開始嘗試增大Epoch及 Batch size   

(4)訓練集使用237張相片,驗證集使用26張,比例為0.9:0.1





三、成果展示 (介紹成果的特點為何，並撰寫心得。)



(1)各次訓練結果整理如下表:







(2)使用已訓練之模型及權重,進行辨識,照片代號說明如下:




(3)不同訓練次數後之辨識結果: (因前4次Epoch太少,又未使用前次權重,辨識結果很差,不列出)









四、結論 (總結本次專題的問題與結果)



[1] 受限於硬體的效能不足,只能採用較低的Epoch及Batch size ,配合使用前次訓練的權重,分辨的成果有改善



[2] 某些Epoch的loss及val loss會有突然升高(如4th訓練之Epoch12,19,20  , 5th訓練之Epoch13,15  , 6th訓練之Epoch12,13,19,20 ) ,上網查了應該是局部過擬合現象



[3] 第七次訓練,loss下降服幅度趨緩,同時val loss還是有突然升高的現象,在測試相片時,有在訓練集的test-org及test0,皆找到3個框(boxes) ; 使用強化曝光未在訓練集的test1,仍然未能找到boxes ,需要在訓練集及於驗證集內,盡量增加多樣化的相片



[4] 下一步計劃持續改善模型,待辨識度更正確後,進行video檔的測試,如果效果良好,便可以部署到jetson nano等終端設備上,實時監督生產線上的組裝機台



五、期末專題作者資訊 (請附上作者資訊)



個人Github連結 : https://github.com/wangyc62/1st-DL-CVMarathon/tree/master/%E6%9C%9F%E6%9C%AB%E5%B0%88%E9%A1%8C-%E4%B8%8A%E5%82%B3%E7%89%88  




個人在百日馬拉松顯示名稱 : wangyc62
分享
留言(1)
Mora
2020/03/05
超棒的把實際所學應用到實際工作所需的現場，因為硬體效能的關係，發現訓練的 epoch 數量真的不多，也可以在colab上面運行看看，使用google的資源，調大epoch數量看訓練出來的模型較果如何。