深度學習與電腦視覺期末專題-芒果辨識_Eddie
2020/03/08
一、專題摘要 (解釋實作與說明需要解決的問題，限300~500字。)
1. 期末專題主題 ：芒果辨識

2. 期末專題基本目標：利用Day41的程式訓練模型來辨識芒果。

(1)資料集：芒果照片(公開資料集)。

(2)使用Keras Yolov3訓練模型（依照電腦GPU規格，可以選擇colab或本機端訓練）。

(3)訓練後模型，用來預測未經訓練的芒果的圖片，以達到辨識芒果的位置並標示出來。





二、實作方法介紹 (介紹使用的程式碼、模組，並附上實作過程與結果的截圖，需圖文並茂。)
1. 資料集

1-1芒果圖片來源，網址：http://acquire.cqu.edu.au:8080/vital/access/manager/Repository/cqu:17570

下載資料集並解壓縮，資料集的目錄結構類似PASCAL VOC數據集，總共有1730張圖片，train有1300張；val有130張；而test有300張。








1-2使用LabelImg將芒果進行標註，並存成Yolo訓練用的txt格式。(資料集本身也有提供已經標記好的yolo訓練用的格式)




2. 使用的程式碼介紹

2-1 使用Day41_train_yolov3_Sample.ipynb進行改寫。類別只有一類，即Mango。




2-2 重新計算anchors:使用kmeans.py重新計算anchors，並存成yolo_mango_anchors1.py(可以嘗試使用不同anchors結果,看模型有無差異)。





2-3模型訓練：基本上跟Day41_train_yolov3_Sample.ipynb。只是在原先生成2007_train.txt的地方調整成2020_train.txt、2020_val.txt及2020_test.txt。




2-4 物件辨識：使用2020_test.txt裡的圖片進行辨識。




三、成果展示 (介紹成果的特點為何，並撰寫心得。)
3-1 訓練過程：整體的訓練花費的時間有點長(因此沒進行增加epoch次數)。


3-2 嘗試調整yolo.py裡面的iou值，看不同的iou值的辨識差異(iou=0.4 及0.45的差異)

iou=0.4




iou=0.45


就單這張照片來看，兩者都能準確辨識結果。雖然iou=0.4有重複框選的問題。



3-3 不同的anchors對辨識的影像(iou皆為0.45)



anchors = [28,33, 33,37, 36,45, 41,53, 41,39, 45,46, 51,53, 51,61, 61,67]


anchors = [15,19,  21,24,  31,34,  34,45,  39,40,  45,54,  46,46,  56,62,  58,64]


從結果來看第一個的anchors結果比較好(沒有重複框)。



3-4其他圖片的辨識結果(以iou=0.45 及anchors = [28,33, 33,37, 36,45, 41,53, 41,39, 45,46, 51,53, 51,61, 61,67] 作為展示)






左邊這張圖，還是有很多目標物辨識不出來。




四、結論 (總結本次專題的問題與結果)
使用D41範例調整後，辨識效果尚可。mAP值為88.96%。目前還有一些參數可能要再調整及訓練，例如資料擴增或是調整iou、score值及epoch次數。不過從這次的期末專題中，自己從找open data到自己標記資料最後自己訓練模型，真的獲益良多。雖然因為嘗試太多次訓練，而導致被colab降速到只能用cpu訓練。果然要訓練還是要準備好一點的GPU，使用1050Ti實在是跑不起來(汗)。

未來模型如果訓練好，應該可以衍伸用來計算芒果產量的議題。






五、期末專題作者資訊 (請附上作者資訊)



1. 個人Github連結  

https://github.com/Jun-ShanLai/1st-DL-CVMarathon



2. 個人在百日馬拉松顯示名稱 　Eddie

分享
留言(1)
楊哲寧
2020/03/15
您好，有鑒於訓練影像只有1000多張，效果已經算相當不錯，您的應用場景也相當有趣且有實用價值！
我這樣看起來其實影像中有許多小物件，且芒果成熟前與葉片顏色相當接近，可能需要更多的訓練資料來提升整體表現，也可以嘗試精度更高的模型，亦或是手動更改模型結構，運用更大的輸入影像與Feature Map來預測。